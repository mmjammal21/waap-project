import pandas as pd
import numpy as np
import glob
import os
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø± ---
DATA_PATH = '/home/malik/graduation_project/data/waap_dataset_2026/'
SAVE_PATH = '/home/malik/graduation_project/data'

print("ğŸš€ Starting FINAL AI Training (Precision Mapping Mode)...")

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø±Ø§Ù…) ---
all_files = glob.glob(os.path.join(DATA_PATH, "*.csv"))
if not all_files:
    print("âŒ No CSV files found!")
    exit()

# Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ 3 Ù…Ù„ÙØ§Øª ÙƒØ¹ÙŠÙ†Ø© Ù‚ÙˆÙŠØ©
selected_files = all_files[:3]
print(f"ğŸ“‚ Loading data from {len(selected_files)} files...")

df_list = []
for file in selected_files:
    try:
        # Ù†Ù‚Ø±Ø£ 150 Ø£Ù„Ù Ø³Ø·Ø± ÙÙ‚Ø· Ù„Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø±Ø§Ù…
        df = pd.read_csv(file, nrows=150000)
        df_list.append(df)
    except Exception as e:
        print(f"âš ï¸ Skipped {os.path.basename(file)}")

full_df = pd.concat(df_list, ignore_index=True)

# --- 3. ØªÙ†Ø¸ÙŠÙ ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ù‡Ù†Ø§ ÙŠÙƒÙ…Ù† Ø§Ù„Ø³Ø±!) ---
# Ù‚Ù…Øª Ø¨Ù†Ø³Ø® Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø­Ø±ÙÙŠØ§Ù‹ Ù…Ù† ØµÙˆØ±ØªÙƒ
# Ø§Ù„Ù…ÙØªØ§Ø­ (ÙŠØ³Ø§Ø±): Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø°ÙŠ ÙŠØ±ÙŠØ¯Ù‡ Ø§Ù„ÙƒÙˆØ¯
# Ø§Ù„Ù‚ÙŠÙ…Ø© (ÙŠÙ…ÙŠÙ†): Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ù„ÙØ§ØªÙƒ
column_mapping = {
    'flow_duration': 'flow_duration',   # Ù…Ø·Ø§Ø¨Ù‚
    'header_length': 'Header_Length',   # ÙƒØ§Ù† ÙŠØ³Ø¨Ø¨ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©
    'protocol_type': 'Protocol Type',   # ÙƒØ§Ù† ÙŠØ³Ø¨Ø¨ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© (ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø§ÙØ©)
    'duration': 'Duration',             # ÙƒØ§Ù† ÙŠØ³Ø¨Ø¨ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© (Ø­Ø±Ù ÙƒØ¨ÙŠØ±)
    'rate': 'Rate'                      # ÙƒØ§Ù† ÙŠØ³Ø¨Ø¨ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© (Ø­Ø±Ù ÙƒØ¨ÙŠØ±)
}

print("ğŸ”§ Mapping columns correctly...")
final_df = pd.DataFrame()

# Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
for target_col, source_col in column_mapping.items():
    if source_col in full_df.columns:
        final_df[target_col] = full_df[source_col]
    else:
        print(f"âŒ CRITICAL ERROR: Column {source_col} not found!")
        exit()

# Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© (Label)
if 'label' in full_df.columns:
    final_df['label'] = full_df['label']
else:
    print("âŒ Error: 'label' column not found!")
    exit()

# --- 4. Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø±Ø§Ù… (Sampling) ---
# Ø¥Ø°Ø§ Ø²Ø§Ø¯Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù† 300 Ø£Ù„ÙØŒ Ù†Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
if len(final_df) > 300000:
    print("âœ‚ï¸ Optimizing dataset size for RAM safety...")
    final_df = final_df.sample(n=300000, random_state=42)

# ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ…
X = final_df.drop('label', axis=1)
y = final_df['label']
X = X.replace([np.inf, -np.inf], np.nan).fillna(0)

# --- 5. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ---
print(f"ğŸ“Š Training on {len(X)} clean records...")

le = LabelEncoder()
y_encoded = le.fit_transform(y.astype(str))

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

print("ğŸ§  Training Random Forest (This is the magic moment)...")
model = RandomForestClassifier(n_estimators=40, max_depth=20, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# --- 6. Ø§Ù„Ù†ØªÙŠØ¬Ø© ---
print("\nğŸ” Evaluating...")
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("="*40)
print(f"âœ… FINAL MODEL ACCURACY: {accuracy * 100:.2f}%")
print("="*40)

print("\nğŸ’¾ Saving High-Performance Model...")
joblib.dump(model, os.path.join(SAVE_PATH, 'waap_model.pkl'))
joblib.dump(le, os.path.join(SAVE_PATH, 'label_encoder.pkl'))
print("ğŸ‰ SYSTEM UPGRADED SUCCESSFULLY!")
