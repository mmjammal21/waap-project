import pandas as pd
import numpy as np
import glob
import os
import joblib
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø± ---
DATA_PATH = '/home/malik/graduation_project/data/waap_dataset_2026/'
SAVE_PATH = '/home/malik/graduation_project/data'

print("ğŸš€ Starting ULTIMATE AI Training (Expanded Features Mode)...")

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
all_files = glob.glob(os.path.join(DATA_PATH, "*.csv"))
if not all_files:
    print("âŒ No CSV files found!")
    exit()

# Ù†Ø£Ø®Ø° 3 Ù…Ù„ÙØ§Øª ÙƒØ¹ÙŠÙ†Ø©
selected_files = all_files[:3]
print(f"ğŸ“‚ Loading data from {len(selected_files)} files...")

df_list = []
for file in selected_files:
    try:
        # Ù†Ù‚Ø±Ø£ 150 Ø£Ù„Ù Ø³Ø·Ø±
        df = pd.read_csv(file, nrows=150000)
        df_list.append(df)
    except Exception as e:
        print(f"âš ï¸ Skipped {os.path.basename(file)}")

full_df = pd.concat(df_list, ignore_index=True)

# --- 3. Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙˆØ³Ø¹Ø© (The Secret Sauce) ---
# Ù‚Ù…Øª Ø¨Ø¥Ø¶Ø§ÙØ© Ø£Ù‡Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ ØµÙˆØ±ØªÙƒ
column_mapping = {
    # Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    'flow_duration': 'flow_duration',
    'header_length': 'Header_Length',
    'protocol_type': 'Protocol Type',
    'duration': 'Duration',
    'rate': 'Rate',
    
    # Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© (Ù„Ø±ÙØ¹ Ø§Ù„Ø¯Ù‚Ø©)
    'srate': 'Srate',       # Source Rate
    'drate': 'Drate',       # Destination Rate
    'fin_flag': 'fin_flag_number',
    'syn_flag': 'syn_flag_number',
    'ack_flag': 'ack_flag_number',
    'max_size': 'Max',      # Maximum packet size
    'avg_size': 'AVG',      # Average packet size
    'std_dev': 'Std',       # Standard Deviation (Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹)
    'magnitude': 'Magnitue' # (Ù…ÙƒØªÙˆØ¨Ø© Ù‡ÙƒØ°Ø§ ÙÙŠ Ø§Ù„Ø¯Ø§ØªØ§ ØªØ¨Ø¹ØªÙƒ)
}

print("ğŸ”§ Mapping extended features...")
final_df = pd.DataFrame()

# Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©
for target_col, source_col in column_mapping.items():
    if source_col in full_df.columns:
        final_df[target_col] = full_df[source_col]
    else:
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¹Ù…ÙˆØ¯Ø§Ù‹ Ø«Ø§Ù†ÙˆÙŠØ§Ù‹ØŒ Ù†Ù…Ù„Ø£Ù‡ Ø¨ØµÙØ± Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬
        print(f"âš ï¸ Note: Column {source_col} not found. Filling with 0.")
        final_df[target_col] = 0

# Ø¥Ø¶Ø§ÙØ© Label
if 'label' in full_df.columns:
    final_df['label'] = full_df['label']
else:
    print("âŒ Error: 'label' column not found!")
    exit()

# --- 4. Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ø±Ø§Ù… ---
if len(final_df) > 300000:
    print("âœ‚ï¸ Optimizing dataset size for RAM safety...")
    final_df = final_df.sample(n=300000, random_state=42)

X = final_df.drop('label', axis=1)
y = final_df['label']
X = X.replace([np.inf, -np.inf], np.nan).fillna(0)

# --- 5. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ---
print(f"ğŸ“Š Training on {len(X)} records with {len(X.columns)} features...")

le = LabelEncoder()
y_encoded = le.fit_transform(y.astype(str))

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

print("ğŸ§  Training Random Forest (High Precision)...")
model = RandomForestClassifier(n_estimators=50, max_depth=25, random_state=42, n_jobs=-1)
model.fit(X_train, y_train)

# --- 6. Ø§Ù„Ù†ØªÙŠØ¬Ø© ---
print("\nğŸ” Evaluating...")
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print("="*40)
print(f"âœ… MODEL ACCURACY: {accuracy * 100:.2f}%")
print("="*40)

print("\nğŸ’¾ Saving Enhanced Model...")
# Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
joblib.dump(model, os.path.join(SAVE_PATH, 'waap_model.pkl'))
# Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ (Encoder)
joblib.dump(le, os.path.join(SAVE_PATH, 'label_encoder.pkl'))
print("ğŸ‰ SYSTEM UPGRADED! Your AI is now much smarter.")
